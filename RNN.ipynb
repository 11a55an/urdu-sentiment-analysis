{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"%cd '/kaggle/input/urdu-comments-classification'","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:59:32.111785Z","iopub.execute_input":"2024-06-06T08:59:32.112201Z","iopub.status.idle":"2024-06-06T08:59:32.121140Z","shell.execute_reply.started":"2024-06-06T08:59:32.112164Z","shell.execute_reply":"2024-06-06T08:59:32.119966Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"/kaggle/input/urdu-comments-classification\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:58:14.081657Z","iopub.execute_input":"2024-06-06T08:58:14.082053Z","iopub.status.idle":"2024-06-06T08:58:14.489347Z","shell.execute_reply.started":"2024-06-06T08:58:14.082024Z","shell.execute_reply":"2024-06-06T08:58:14.488159Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train = pd.read_excel(\"train.xlsx\")","metadata":{"execution":{"iopub.status.busy":"2024-06-06T08:59:45.294316Z","iopub.execute_input":"2024-06-06T08:59:45.294718Z","iopub.status.idle":"2024-06-06T08:59:46.154622Z","shell.execute_reply.started":"2024-06-06T08:59:45.294688Z","shell.execute_reply":"2024-06-06T08:59:46.153734Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"test = pd.read_excel(\"test.xlsx\")\nvalid = pd.read_excel(\"valid.xlsx\")","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:00:24.143044Z","iopub.execute_input":"2024-06-06T09:00:24.143457Z","iopub.status.idle":"2024-06-06T09:00:24.506936Z","shell.execute_reply.started":"2024-06-06T09:00:24.143428Z","shell.execute_reply":"2024-06-06T09:00:24.505943Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:00:32.240527Z","iopub.execute_input":"2024-06-06T09:00:32.241001Z","iopub.status.idle":"2024-06-06T09:00:32.256680Z","shell.execute_reply.started":"2024-06-06T09:00:32.240967Z","shell.execute_reply":"2024-06-06T09:00:32.255383Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                             comment target\n0  متفق  افراد کو جوڑنا سب کو ضرورت کی جگہ پر  کر...    neu\n1           شاھد بایھی اپ کو ون ڈےکرکٹ میں واپس آجاے    neu\n2                            سر مجھے بھی ایک  دے دیں    neu\n3                شاہد بھاہی جنرل راحیل کی طرح شیر ہے    neu\n4                                     پوں پوں آفریدی    neu","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>متفق  افراد کو جوڑنا سب کو ضرورت کی جگہ پر  کر...</td>\n      <td>neu</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>شاھد بایھی اپ کو ون ڈےکرکٹ میں واپس آجاے</td>\n      <td>neu</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>سر مجھے بھی ایک  دے دیں</td>\n      <td>neu</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>شاہد بھاہی جنرل راحیل کی طرح شیر ہے</td>\n      <td>neu</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>پوں پوں آفریدی</td>\n      <td>neu</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:00:36.888232Z","iopub.execute_input":"2024-06-06T09:00:36.888693Z","iopub.status.idle":"2024-06-06T09:00:36.899245Z","shell.execute_reply.started":"2024-06-06T09:00:36.888660Z","shell.execute_reply":"2024-06-06T09:00:36.898184Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                             comment target\n0  زمان خان نے آوٹ نہ کر کے اچھا کیا باقی سب گیم ...    neu\n1  اس غریب کے پاس کوئئ سفارش نہیں تبھی اس بیچارے ...    neu\n2  پاکستانی ٹیم میں کمزور پلیئر امام الحق محمد نو...    neu\n3  اچھا تھمب نیل میں لڑکی دکھانا لازمی ہے کیا بات ہے    neu\n4     آپ میری تجویز پر عمل کریں گے  مجھے بڑی امید ھے    neu","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>زمان خان نے آوٹ نہ کر کے اچھا کیا باقی سب گیم ...</td>\n      <td>neu</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>اس غریب کے پاس کوئئ سفارش نہیں تبھی اس بیچارے ...</td>\n      <td>neu</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>پاکستانی ٹیم میں کمزور پلیئر امام الحق محمد نو...</td>\n      <td>neu</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>اچھا تھمب نیل میں لڑکی دکھانا لازمی ہے کیا بات ہے</td>\n      <td>neu</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>آپ میری تجویز پر عمل کریں گے  مجھے بڑی امید ھے</td>\n      <td>neu</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"valid.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:00:41.586478Z","iopub.execute_input":"2024-06-06T09:00:41.586884Z","iopub.status.idle":"2024-06-06T09:00:41.596997Z","shell.execute_reply.started":"2024-06-06T09:00:41.586852Z","shell.execute_reply":"2024-06-06T09:00:41.595952Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                             comment target\n0  کچے کیلے یہاں ناروے میں عام دکانوں سے کٹی حالت...    neu\n1  کہیں سے بھی ملیں کیلے بس مل جائیں میں ریکوئسٹ ...    neu\n2  آپ نے بھی سعود بھائی کی ترکیب سے بنائے تھے جاسمن؟    neu\n3  کٹے ہوئے خشک کیلے پکوڑوں کی اس ترکیب کے لیے من...    neu\n4  سعود بھائی اگر آپ وعدہ کریں کہ اسی طرح تفصیل س...    neu","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>کچے کیلے یہاں ناروے میں عام دکانوں سے کٹی حالت...</td>\n      <td>neu</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>کہیں سے بھی ملیں کیلے بس مل جائیں میں ریکوئسٹ ...</td>\n      <td>neu</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>آپ نے بھی سعود بھائی کی ترکیب سے بنائے تھے جاسمن؟</td>\n      <td>neu</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>کٹے ہوئے خشک کیلے پکوڑوں کی اس ترکیب کے لیے من...</td>\n      <td>neu</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>سعود بھائی اگر آپ وعدہ کریں کہ اسی طرح تفصیل س...</td>\n      <td>neu</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(train.shape,\ntest.shape,\nvalid.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:01:18.034069Z","iopub.execute_input":"2024-06-06T09:01:18.034933Z","iopub.status.idle":"2024-06-06T09:01:18.040198Z","shell.execute_reply.started":"2024-06-06T09:01:18.034899Z","shell.execute_reply":"2024-06-06T09:01:18.039084Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"(6399, 2) (2001, 2) (1602, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"train = train.drop_duplicates()\ntest = test.drop_duplicates()\nvalid = valid.drop_duplicates()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:01:57.706714Z","iopub.execute_input":"2024-06-06T09:01:57.707119Z","iopub.status.idle":"2024-06-06T09:01:57.731242Z","shell.execute_reply.started":"2024-06-06T09:01:57.707086Z","shell.execute_reply":"2024-06-06T09:01:57.730181Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(train.shape,\ntest.shape,\nvalid.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:02:04.750844Z","iopub.execute_input":"2024-06-06T09:02:04.751747Z","iopub.status.idle":"2024-06-06T09:02:04.757005Z","shell.execute_reply.started":"2024-06-06T09:02:04.751710Z","shell.execute_reply":"2024-06-06T09:02:04.755837Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"(6335, 2) (1984, 2) (1593, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install urduhack","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:03:28.545838Z","iopub.execute_input":"2024-06-06T09:03:28.546306Z","iopub.status.idle":"2024-06-06T09:03:52.097383Z","shell.execute_reply.started":"2024-06-06T09:03:28.546271Z","shell.execute_reply":"2024-06-06T09:03:52.095995Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Collecting urduhack\n  Downloading urduhack-1.1.1-py3-none-any.whl.metadata (7.2 kB)\nCollecting tf2crf (from urduhack)\n  Downloading tf2crf-0.1.33-py2.py3-none-any.whl.metadata (1.9 kB)\nCollecting tensorflow-datasets~=3.1 (from urduhack)\n  Downloading tensorflow_datasets-3.2.1-py3-none-any.whl.metadata (4.8 kB)\nCollecting Click~=7.1 (from urduhack)\n  Downloading click-7.1.2-py2.py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from urduhack) (2023.12.25)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets~=3.1->urduhack) (1.4.0)\nRequirement already satisfied: attrs>=18.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets~=3.1->urduhack) (23.2.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets~=3.1->urduhack) (0.3.8)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets~=3.1->urduhack) (1.0.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets~=3.1->urduhack) (1.26.4)\nRequirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets~=3.1->urduhack) (2.3)\nRequirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets~=3.1->urduhack) (3.20.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets~=3.1->urduhack) (2.32.3)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets~=3.1->urduhack) (1.16.0)\nRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets~=3.1->urduhack) (0.14.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets~=3.1->urduhack) (2.4.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets~=3.1->urduhack) (4.66.4)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets~=3.1->urduhack) (1.14.1)\nRequirement already satisfied: tensorflow>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from tf2crf->urduhack) (2.15.0)\nCollecting tensorflow-addons>=0.8.2 (from tf2crf->urduhack)\n  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets~=3.1->urduhack) (2024.2.2)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (23.5.26)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (21.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (69.0.3)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (4.9.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (2.15.1)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow>=2.1.0->tf2crf->urduhack)\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting typeguard<3.0.0,>=2.7 (from tensorflow-addons>=0.8.2->tf2crf->urduhack)\n  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow-datasets~=3.1->urduhack) (1.62.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.1.0->tf2crf->urduhack) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.1.0->tf2crf->urduhack) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.1.0->tf2crf->urduhack) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.1.0->tf2crf->urduhack) (3.5.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.1.0->tf2crf->urduhack) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow>=2.1.0->tf2crf->urduhack) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow>=2.1.0->tf2crf->urduhack) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->tf2crf->urduhack) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->tf2crf->urduhack) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->tf2crf->urduhack) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->tf2crf->urduhack) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->tf2crf->urduhack) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->tf2crf->urduhack) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow>=2.1.0->tf2crf->urduhack) (3.2.2)\nDownloading urduhack-1.1.1-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.5/105.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorflow_datasets-3.2.1-py3-none-any.whl (3.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading tf2crf-0.1.33-py2.py3-none-any.whl (7.3 kB)\nDownloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nInstalling collected packages: typeguard, keras, Click, tensorflow-addons, tensorflow-datasets, tf2crf, urduhack\n  Attempting uninstall: typeguard\n    Found existing installation: typeguard 4.1.5\n    Uninstalling typeguard-4.1.5:\n      Successfully uninstalled typeguard-4.1.5\n  Attempting uninstall: keras\n    Found existing installation: keras 3.3.3\n    Uninstalling keras-3.3.3:\n      Successfully uninstalled keras-3.3.3\n  Attempting uninstall: Click\n    Found existing installation: click 8.1.7\n    Uninstalling click-8.1.7:\n      Successfully uninstalled click-8.1.7\n  Attempting uninstall: tensorflow-datasets\n    Found existing installation: tensorflow-datasets 4.9.4\n    Uninstalling tensorflow-datasets-4.9.4:\n      Successfully uninstalled tensorflow-datasets-4.9.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.9.0 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\ndask 2024.5.2 requires click>=8.1, but you have click 7.1.2 which is incompatible.\nfiona 1.9.6 requires click~=8.0, but you have click 7.1.2 which is incompatible.\nfitter 1.7.0 requires click<9.0.0,>=8.1.6, but you have click 7.1.2 which is incompatible.\nflask 3.0.3 requires click>=8.1.3, but you have click 7.1.2 which is incompatible.\nkfp 2.5.0 requires click<9,>=8.0.0, but you have click 7.1.2 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.3 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\nydata-profiling 4.6.4 requires typeguard<5,>=4.1.2, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Click-7.1.2 keras-2.15.0 tensorflow-addons-0.23.0 tensorflow-datasets-3.2.1 tf2crf-0.1.33 typeguard-2.13.3 urduhack-1.1.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install demoji","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:03:52.100172Z","iopub.execute_input":"2024-06-06T09:03:52.100659Z","iopub.status.idle":"2024-06-06T09:04:06.632878Z","shell.execute_reply.started":"2024-06-06T09:03:52.100611Z","shell.execute_reply":"2024-06-06T09:04:06.631659Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Collecting demoji\n  Downloading demoji-1.1.0-py3-none-any.whl.metadata (9.2 kB)\nDownloading demoji-1.1.0-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: demoji\nSuccessfully installed demoji-1.1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import demoji\nimport re\n\nfrom urduhack.preprocessing import replace_urls\nfrom urduhack.preprocessing import replace_numbers\nfrom urduhack.preprocessing import remove_punctuation\nfrom urduhack.preprocessing import remove_accents\nfrom urduhack.preprocessing import remove_english_alphabets\nfrom urduhack.preprocessing import normalize_whitespace\nfrom urduhack.normalization import normalize\n\ndef clean_comment(comment):\n\n    comment = demoji.replace(comment,\"\")\n\n    comment = re.sub(r'@[A-Za-z0-9]+', '', comment)\n\n    comment = re.sub(r'#[A-Za-z0-9]*', '', comment)\n\n    comment = replace_urls(comment,replace_with=\"\")\n\n    comment = replace_numbers(comment,replace_with=\"\")\n\n    comment = remove_accents(comment)\n\n    comment = remove_english_alphabets(comment)\n\n    comment = normalize_whitespace(comment)\n\n    comment = remove_punctuation(comment)\n\n    comment = normalize(comment)\n\n    comment = re.sub(r'\\+', '', comment)\n\n    comment = re.sub(r'\\=', '', comment)\n\n    return comment","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:04:38.592259Z","iopub.execute_input":"2024-06-06T09:04:38.592737Z","iopub.status.idle":"2024-06-06T09:04:51.972437Z","shell.execute_reply.started":"2024-06-06T09:04:38.592700Z","shell.execute_reply":"2024-06-06T09:04:51.971256Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"2024-06-06 09:04:40.494740: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-06 09:04:40.494858: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-06 09:04:40.625775: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/opt/conda/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n\nTensorFlow Addons (TFA) has ended development and introduction of new features.\nTFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\nPlease modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n\nFor more information see: https://github.com/tensorflow/addons/issues/2807 \n\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"for i in train.index:\n    a = train['comment'][i]\n    b = clean_comment(a)\n    train.loc[[i],['comment']] = b\n\nfor i in valid.index:\n    a = valid['comment'][i]\n    b = clean_comment(a)\n    valid.loc[[i],['comment']] = b\n\nfor i in test.index:\n    a = test['comment'][i]\n    b = clean_comment(a)\n    test.loc[[i],['comment']] = b","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:04:59.219745Z","iopub.execute_input":"2024-06-06T09:04:59.220472Z","iopub.status.idle":"2024-06-06T09:05:18.065160Z","shell.execute_reply.started":"2024-06-06T09:04:59.220439Z","shell.execute_reply":"2024-06-06T09:05:18.064254Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"stop_words = set(\"\"\"\n\n آ آئی آئیں آئے آتا آتی آتے آداب آدھ آدھا آدھی آدھے آس آمدید آنا آنسہ آنی آنے\n آپ آگے آہ آہا آیا اب ابھی ابے اتوار ارب اربویں ارے اس اسکا اسکی اسکے اسی اسے اف\n افوہ الاول البتہ الثانی الحرام السلام الف المکرم ان اندر انکا انکی انکے انہوں انہی انہیں اوئے اور\n اوپر اوہو اپ اپنا اپنوں اپنی اپنے اپنےآپ اکبر اکثر اگر اگرچہ اگست اہاہا ایسا ایسی ایسے ایک بائیں\n بار بارے بالکل باوجود باہر بج بجے بخیر برسات بشرطیکہ بعد بعض بغیر بلکہ بن بنا بناؤ بند\n بڑی بھر بھریں بھی بہار بہت بہتر بیگم تاکہ تاہم تب تجھ تجھی تجھے ترا تری تلک تم تمام\n تمہارا تمہاروں تمہاری تمہارے تمہیں تو تک تھا تھی تھیں تھے تہائی تیرا تیری تیرے تین جا جاؤ\n جائیں جائے جاتا جاتی جاتے جانی جانے جب جبکہ جدھر جس جسے جن جناب جنہوں جنہیں جو جہاں جی\n جیسا جیسوں جیسی جیسے جیٹھ حالانکہ حالاں حصہ حضرت خاطر خالی خدا خزاں خواہ خوب خود دائیں درمیان\n دریں دو دوران دوسرا دوسروں دوسری دوشنبہ دوں دکھائیں دگنا دی دیئے دیا دیتا دیتی دیتے دیر دینا دینی\n دینے دیکھو دیں دیے دے ذریعے رکھا رکھتا رکھتی رکھتے رکھنا رکھنی رکھنے رکھو رکھی رکھے رہ رہا\n رہتا رہتی رہتے رہنا رہنی رہنے رہو رہی رہیں رہے ساتھ سامنے ساڑھے سب سبھی سراسر سلام سمیت سوا\n سوائے سکا سکتا سکتے سہ سہی سی سے شام شاید شکریہ صاحب صاحبہ صرف ضرور طرح طرف طور\n علاوہ عین فروری فقط فلاں فی قبل قطا لئے لائی لائے لاتا لاتی لاتے لانا لانی لانے لایا لو\n لوجی لوگوں لگ لگا لگتا لگتی لگی لگیں لگے لہذا لی لیا لیتا لیتی لیتے لیکن لیں لیے\n لے ماسوا مت مجھ مجھی مجھے محترم محترمہ محترمی محض مرا مرحبا مری مرے مزید مس مسز مسٹر مطابق\n مطلق مل منٹ منٹوں مکرمی مگر مگھر مہربانی میرا میروں میری میرے میں نا نزدیک نما نو نومبر\n نہ نہیں نیز نیچے نے و وار واسطے واقعی والا والوں والی والے واہ وجہ ورنہ وعلیکم وغیرہ ولے\n وگرنہ وہ وہاں وہی وہیں ویسا ویسے ویں پاس پایا پر پس پلیز پون پونا پونی پونے پھاگن\n پھر پہ پہر پہلا پہلی پہلے پیر پیچھے چاہئے چاہتے چاہیئے چاہے چلا چلو چلیں چلے چناچہ چند چونکہ\n چوگنی چکی چکیں چکے چہارشنبہ چیت ڈالنا ڈالنی ڈالنے ڈالے کئے کا کاتک کاش کب کبھی کدھر کر\n کرتا کرتی کرتے کرم کرنا کرنے کرو کریں کرے کس کسی کسے کل کم کن کنہیں کو کوئی کون\n کونسا کونسے کچھ کہ کہا کہاں کہہ کہی کہیں کہے کی کیا کیسا کیسے کیونکر کیونکہ کیوں کیے\n کے گئی گئے گا گرما گرمی گنا گو گویا گھنٹا گھنٹوں گھنٹے گی گیا ہائیں ہائے ہاڑ ہاں ہر\n ہرچند ہرگز ہزار ہفتہ ہم ہمارا ہماری ہمارے ہمی ہمیں ہو ہوئی ہوئیں ہوئے ہوا ہوبہو ہوتا ہوتی\n ہوتیں ہوتے ہونا ہونگے ہونی ہونے ہوں ہی ہیلو ہیں ہے یا یات یعنی یک یہ یہاں یہی یہیں\n\n\n\"\"\".split())\n\ndef remove_stopwords(text):\n    filtered_words = [word for word in text.split() if word not in stop_words]\n    return \" \".join(filtered_words)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:05:35.086441Z","iopub.execute_input":"2024-06-06T09:05:35.087035Z","iopub.status.idle":"2024-06-06T09:05:35.097083Z","shell.execute_reply.started":"2024-06-06T09:05:35.087000Z","shell.execute_reply":"2024-06-06T09:05:35.096037Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train[\"comment\"] = train.comment.map(remove_stopwords)\nvalid[\"comment\"] = valid.comment.map(remove_stopwords)\ntest[\"comment\"] = test.comment.map(remove_stopwords)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:05:43.176748Z","iopub.execute_input":"2024-06-06T09:05:43.177168Z","iopub.status.idle":"2024-06-06T09:05:43.241510Z","shell.execute_reply.started":"2024-06-06T09:05:43.177136Z","shell.execute_reply":"2024-06-06T09:05:43.240563Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import urduhack\nurduhack.download()\nfrom urduhack.models.lemmatizer import lemmatizer\n\ndef lemitizeStr(text):\n    lemme_txt = \"\"\n    temp = lemmatizer.lemma_lookup(text)\n    for t in temp:\n        lemme_txt += t[0] + \" \"\n\n    return lemme_txt","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:08:14.207064Z","iopub.execute_input":"2024-06-06T09:08:14.207831Z","iopub.status.idle":"2024-06-06T09:08:17.122080Z","shell.execute_reply.started":"2024-06-06T09:08:14.207794Z","shell.execute_reply":"2024-06-06T09:08:17.121030Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Downloading data from https://github.com/urduhack/resources/releases/download/word_tokenizer/word_tokenizer.zip\n36788015/36788015 [==============================] - 0s 0us/step\nDownloading data from https://github.com/urduhack/resources/releases/download/pos_tagger/pos_tagger.zip\n2761433/2761433 [==============================] - 0s 0us/step\nDownloading data from https://github.com/urduhack/resources/releases/download/ner/ner.zip\n11723346/11723346 [==============================] - 0s 0us/step\nDownloading data from https://github.com/urduhack/resources/releases/download/lemmatizer/ur_lemma_lookup.zip\n89078/89078 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"train[\"comment\"] = train.comment.map(lemitizeStr)\nvalid[\"comment\"] = valid.comment.map(lemitizeStr)\ntest[\"comment\"] = test.comment.map(lemitizeStr)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:08:18.649827Z","iopub.execute_input":"2024-06-06T09:08:18.650238Z","iopub.status.idle":"2024-06-06T09:08:18.747463Z","shell.execute_reply.started":"2024-06-06T09:08:18.650207Z","shell.execute_reply":"2024-06-06T09:08:18.746491Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:11:26.573810Z","iopub.execute_input":"2024-06-06T09:11:26.574247Z","iopub.status.idle":"2024-06-06T09:11:26.592288Z","shell.execute_reply.started":"2024-06-06T09:11:26.574215Z","shell.execute_reply":"2024-06-06T09:11:26.585861Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"target\nneg    2441\nneu    2026\npos    1868\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"test['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:11:40.274455Z","iopub.execute_input":"2024-06-06T09:11:40.275415Z","iopub.status.idle":"2024-06-06T09:11:40.283821Z","shell.execute_reply.started":"2024-06-06T09:11:40.275380Z","shell.execute_reply":"2024-06-06T09:11:40.282787Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"target\nneg    769\nneu    632\npos    583\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"valid['target'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:11:47.056709Z","iopub.execute_input":"2024-06-06T09:11:47.057422Z","iopub.status.idle":"2024-06-06T09:11:47.065841Z","shell.execute_reply.started":"2024-06-06T09:11:47.057391Z","shell.execute_reply":"2024-06-06T09:11:47.064992Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"target\nneg    616\nneu    504\npos    473\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nclass_label_encoder = LabelEncoder()\n\ntrain['target_encoded'] = class_label_encoder.fit_transform(train['target'])\ntest['target_encoded'] = class_label_encoder.fit_transform(test['target'])\nvalid['target_encoded'] = class_label_encoder.fit_transform(valid['target'])","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:13:35.322951Z","iopub.execute_input":"2024-06-06T09:13:35.323405Z","iopub.status.idle":"2024-06-06T09:13:35.693533Z","shell.execute_reply.started":"2024-06-06T09:13:35.323375Z","shell.execute_reply":"2024-06-06T09:13:35.692640Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"train['target_encoded'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:13:52.900371Z","iopub.execute_input":"2024-06-06T09:13:52.900838Z","iopub.status.idle":"2024-06-06T09:13:52.911539Z","shell.execute_reply.started":"2024-06-06T09:13:52.900803Z","shell.execute_reply":"2024-06-06T09:13:52.910395Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"target_encoded\n0    2441\n1    2026\n2    1868\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"x_train = train[\"comment\"]\nx_test = test[\"comment\"]\nx_valid = valid[\"comment\"]\ny_train = train[[\"target_encoded\"]]\ny_test = test[[\"target_encoded\"]]\ny_valid = valid[[\"target_encoded\"]]","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:15:05.831720Z","iopub.execute_input":"2024-06-06T09:15:05.832560Z","iopub.status.idle":"2024-06-06T09:15:05.842283Z","shell.execute_reply.started":"2024-06-06T09:15:05.832523Z","shell.execute_reply":"2024-06-06T09:15:05.841215Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([train,valid,test])","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:17:41.305857Z","iopub.execute_input":"2024-06-06T09:17:41.306471Z","iopub.status.idle":"2024-06-06T09:17:41.314274Z","shell.execute_reply.started":"2024-06-06T09:17:41.306429Z","shell.execute_reply":"2024-06-06T09:17:41.313186Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:17:46.456492Z","iopub.execute_input":"2024-06-06T09:17:46.456938Z","iopub.status.idle":"2024-06-06T09:17:46.464012Z","shell.execute_reply.started":"2024-06-06T09:17:46.456905Z","shell.execute_reply":"2024-06-06T09:17:46.462832Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"(9912, 3)"},"metadata":{}}]},{"cell_type":"code","source":"from collections import Counter\n\ndef counter_word(text_col):\n    count = Counter()\n    for text in text_col.values:\n        for word in text.split():\n            count[word] += 1\n    return count","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:17:50.439239Z","iopub.execute_input":"2024-06-06T09:17:50.439688Z","iopub.status.idle":"2024-06-06T09:17:50.445710Z","shell.execute_reply.started":"2024-06-06T09:17:50.439653Z","shell.execute_reply":"2024-06-06T09:17:50.444605Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"counter = counter_word(df.comment)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:17:54.109438Z","iopub.execute_input":"2024-06-06T09:17:54.110509Z","iopub.status.idle":"2024-06-06T09:17:54.158516Z","shell.execute_reply.started":"2024-06-06T09:17:54.110463Z","shell.execute_reply":"2024-06-06T09:17:54.157384Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"num_unique_words = len(counter)\nnum_unique_words","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:17:55.359323Z","iopub.execute_input":"2024-06-06T09:17:55.359850Z","iopub.status.idle":"2024-06-06T09:17:55.367809Z","shell.execute_reply.started":"2024-06-06T09:17:55.359800Z","shell.execute_reply":"2024-06-06T09:17:55.366520Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"12362"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\n\ntokenizer = Tokenizer(num_words=num_unique_words)\ntokenizer.fit_on_texts(x_train)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:19:17.170620Z","iopub.execute_input":"2024-06-06T09:19:17.171034Z","iopub.status.idle":"2024-06-06T09:19:17.326814Z","shell.execute_reply.started":"2024-06-06T09:19:17.171003Z","shell.execute_reply":"2024-06-06T09:19:17.325656Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"word_index = tokenizer.word_index","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:19:31.028537Z","iopub.execute_input":"2024-06-06T09:19:31.029505Z","iopub.status.idle":"2024-06-06T09:19:31.033975Z","shell.execute_reply.started":"2024-06-06T09:19:31.029470Z","shell.execute_reply":"2024-06-06T09:19:31.032916Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"len(word_index)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:19:57.903671Z","iopub.execute_input":"2024-06-06T09:19:57.904082Z","iopub.status.idle":"2024-06-06T09:19:57.911207Z","shell.execute_reply.started":"2024-06-06T09:19:57.904050Z","shell.execute_reply":"2024-06-06T09:19:57.909956Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"9175"},"metadata":{}}]},{"cell_type":"code","source":"X_train_seq = tokenizer.texts_to_sequences(x_train)\nX_valid_seq = tokenizer.texts_to_sequences(x_valid)\nX_test_seq = tokenizer.texts_to_sequences(x_test)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:20:35.143908Z","iopub.execute_input":"2024-06-06T09:20:35.144912Z","iopub.status.idle":"2024-06-06T09:20:35.342030Z","shell.execute_reply.started":"2024-06-06T09:20:35.144869Z","shell.execute_reply":"2024-06-06T09:20:35.341085Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\n\nmax_length = 20\nX_train_padded = pad_sequences(X_train_seq, maxlen=max_length, padding=\"post\")\nX_valid_padded = pad_sequences(X_valid_seq, maxlen=max_length, padding=\"post\")\nX_test_padded = pad_sequences(X_test_seq, maxlen=max_length, padding=\"post\")\nX_train_padded.shape, X_valid_padded.shape, X_test_padded.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:22:23.346193Z","iopub.execute_input":"2024-06-06T09:22:23.346845Z","iopub.status.idle":"2024-06-06T09:22:23.408787Z","shell.execute_reply.started":"2024-06-06T09:22:23.346813Z","shell.execute_reply":"2024-06-06T09:22:23.407671Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"((6335, 20), (1593, 20), (1984, 20))"},"metadata":{}}]},{"cell_type":"code","source":"print(x_train.iloc[10])","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:22:40.828667Z","iopub.execute_input":"2024-06-06T09:22:40.829102Z","iopub.status.idle":"2024-06-06T09:22:40.835086Z","shell.execute_reply.started":"2024-06-06T09:22:40.829068Z","shell.execute_reply":"2024-06-06T09:22:40.833883Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"آج ارجنٹینا میچ دیکھ ارجنٹینا جرمنی رکھوں ارجنٹینا برازیل ٹیم فاتح باقی انگلیڈ کھیل مایوس رونی صورتحال سنبھال \n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_train_seq[10])","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:22:47.981493Z","iopub.execute_input":"2024-06-06T09:22:47.981917Z","iopub.status.idle":"2024-06-06T09:22:47.987540Z","shell.execute_reply.started":"2024-06-06T09:22:47.981888Z","shell.execute_reply":"2024-06-06T09:22:47.986415Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"[22, 1256, 3, 37, 1256, 491, 2759, 1256, 794, 2, 524, 149, 4055, 16, 664, 2114, 990, 2115]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_train_padded[10])","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:22:55.590013Z","iopub.execute_input":"2024-06-06T09:22:55.590400Z","iopub.status.idle":"2024-06-06T09:22:55.596423Z","shell.execute_reply.started":"2024-06-06T09:22:55.590372Z","shell.execute_reply":"2024-06-06T09:22:55.595254Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"[  22 1256    3   37 1256  491 2759 1256  794    2  524  149 4055   16\n  664 2114  990 2115    0    0]\n","output_type":"stream"}]},{"cell_type":"code","source":"weight_matrix.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:33:26.809830Z","iopub.execute_input":"2024-06-06T09:33:26.810347Z","iopub.status.idle":"2024-06-06T09:33:26.820076Z","shell.execute_reply.started":"2024-06-06T09:33:26.810306Z","shell.execute_reply":"2024-06-06T09:33:26.818556Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"(12362, 300)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder(sparse=False)\n\n# Fit and transform the data\nencoded_array = encoder.fit_transform(train[['target']])\n\n# Create a DataFrame with the encoded data\ntrain_encoded = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out())\n\n# Fit and transform the data\nencoded_array = encoder.fit_transform(valid[['target']])\n\n# Create a DataFrame with the encoded data\nvalid_encoded = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out())\n\n# Fit and transform the data\nencoded_array = encoder.fit_transform(test[['target']])\n\n# Create a DataFrame with the encoded data\ntest_encoded = pd.DataFrame(encoded_array, columns=encoder.get_feature_names_out())","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:46:36.655688Z","iopub.execute_input":"2024-06-06T09:46:36.656259Z","iopub.status.idle":"2024-06-06T09:46:36.680411Z","shell.execute_reply.started":"2024-06-06T09:46:36.656219Z","shell.execute_reply":"2024-06-06T09:46:36.679213Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"y_train, y_valid, y_test = train_encoded, valid_encoded, test_encoded","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:47:12.293688Z","iopub.execute_input":"2024-06-06T09:47:12.294227Z","iopub.status.idle":"2024-06-06T09:47:12.299988Z","shell.execute_reply.started":"2024-06-06T09:47:12.294186Z","shell.execute_reply":"2024-06-06T09:47:12.298779Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"from gensim.models import KeyedVectors\n\nword2vec = KeyedVectors.load_word2vec_format('/kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin',  binary=True, limit=10 ** 5)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:32:43.991271Z","iopub.execute_input":"2024-06-06T09:32:43.991793Z","iopub.status.idle":"2024-06-06T09:32:46.889504Z","shell.execute_reply.started":"2024-06-06T09:32:43.991753Z","shell.execute_reply":"2024-06-06T09:32:46.888322Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nembedding_dim = 300\nweight_matrix = np.zeros((num_unique_words, embedding_dim))\nfor word, i in tokenizer.word_index.items():\n    try:\n        embedding_vector = word2vec[word]\n        weight_matrix[i] = embedding_vector\n    except KeyError:\n        weight_matrix[i] = np.random.uniform(-5, 5, embedding_dim)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T09:33:18.561240Z","iopub.execute_input":"2024-06-06T09:33:18.561780Z","iopub.status.idle":"2024-06-06T09:33:18.719056Z","shell.execute_reply.started":"2024-06-06T09:33:18.561736Z","shell.execute_reply":"2024-06-06T09:33:18.717990Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing import sequence\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Bidirectional, SimpleRNN, Activation, LSTM, GRU, Embedding, Bidirectional, InputLayer, Conv1D, GlobalMaxPooling1D, Flatten\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\nbatch_size=32\n\nmodel = keras.models.Sequential()\nmodel.add(layers.Embedding(num_unique_words, embedding_dim, weights=[weight_matrix], input_length=max_length))\n\n\n\n# model.add(GRU(200, return_sequences=True))\n# model.add(Dropout(0.3))\n# model.add(GRU(200, return_sequences=True))\n# model.add(Dropout(0.3))\n# model.add(GRU(200, return_sequences=False))\n# model.add(Dropout(0.3))\n\n#     model.add(Conv1D(128, 5, activation='relu'))  # Convolutional layer\n#     model.add(GlobalMaxPooling1D())\n#     model.add(Conv1D(128, 5, activation='relu'))  # Convolutional layer\n#     model.add(GlobalMaxPooling1D())\n#     model.add(Dropout(0.3))\n#     model.add(Conv1D(128, 5, activation='relu'))  # Convolutional layer\n#     model.add(Dropout(0.3))\n#     model.add(GlobalMaxPooling1D())\n#     model.add(Dense(64))\n\nmodel.add(Bidirectional(LSTM(200, return_sequences=True)))\nmodel.add(Dropout(0.3))\nmodel.add(Bidirectional(LSTM(200, return_sequences=True)))\nmodel.add(Dropout(0.3))\nmodel.add(Bidirectional(LSTM(200)))\nmodel.add(Dropout(0.3))\n\n# model.add(SimpleRNN(200, return_sequences=True))\n# model.add(Dropout(0.3))\n# model.add(SimpleRNN(200, return_sequences=True))\n# model.add(Dropout(0.3))\n# model.add(SimpleRNN(200))\n# model.add(Dropout(0.3))\n\n# model.add(Flatten())\n# model.add(Dense(500,activation='relu'))\n# model.add(Dropout(0.3))\n# model.add(Dense(500,activation='relu'))\n# model.add(Dropout(0.3))\n# model.add(Dense(500,activation='relu'))\n# model.add(Dropout(0.3))\n\n\n# model.add(LSTM(128, return_sequences=True))\n# model.add(Dropout(0.3))\n# model.add(LSTM(64, return_sequences=True))\n# model.add(Dropout(0.3))\n# model.add(LSTM(32))\n# model.add(Dropout(0.3))\n\n\nmodel.add(Dense(3, activation='softmax'))\nmodel.summary()\n\nloss = keras.losses.CategoricalCrossentropy(from_logits=False)\noptim = keras.optimizers.Adam(learning_rate=0.008)\nmodel.compile(loss=loss, optimizer=optim)\n\nmodel.fit(X_train_padded, y_train, validation_data = (X_valid_padded,y_valid),batch_size = batch_size, epochs=100, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:50:16.704552Z","iopub.execute_input":"2024-06-06T11:50:16.705277Z","iopub.status.idle":"2024-06-06T12:25:38.971222Z","shell.execute_reply.started":"2024-06-06T11:50:16.705243Z","shell.execute_reply":"2024-06-06T12:25:38.969386Z"},"trusted":true},"execution_count":142,"outputs":[{"name":"stdout","text":"Model: \"sequential_33\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding_33 (Embedding)    (None, 20, 300)           3708600   \n                                                                 \n bidirectional_15 (Bidirect  (None, 20, 400)           801600    \n ional)                                                          \n                                                                 \n dropout_92 (Dropout)        (None, 20, 400)           0         \n                                                                 \n bidirectional_16 (Bidirect  (None, 20, 400)           961600    \n ional)                                                          \n                                                                 \n dropout_93 (Dropout)        (None, 20, 400)           0         \n                                                                 \n bidirectional_17 (Bidirect  (None, 400)               961600    \n ional)                                                          \n                                                                 \n dropout_94 (Dropout)        (None, 400)               0         \n                                                                 \n dense_57 (Dense)            (None, 3)                 1203      \n                                                                 \n=================================================================\nTotal params: 6434603 (24.55 MB)\nTrainable params: 6434603 (24.55 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\nEpoch 1/100\n198/198 - 62s - loss: 1.0479 - val_loss: 1.0747 - 62s/epoch - 315ms/step\nEpoch 2/100\n198/198 - 48s - loss: 0.9033 - val_loss: 1.0591 - 48s/epoch - 245ms/step\nEpoch 3/100\n198/198 - 47s - loss: 0.7337 - val_loss: 1.1564 - 47s/epoch - 239ms/step\nEpoch 4/100\n198/198 - 47s - loss: 0.6427 - val_loss: 1.3399 - 47s/epoch - 239ms/step\nEpoch 5/100\n198/198 - 48s - loss: 0.5479 - val_loss: 1.2926 - 48s/epoch - 244ms/step\nEpoch 6/100\n198/198 - 49s - loss: 0.4802 - val_loss: 1.5449 - 49s/epoch - 247ms/step\nEpoch 7/100\n198/198 - 49s - loss: 0.4355 - val_loss: 1.5094 - 49s/epoch - 246ms/step\nEpoch 8/100\n198/198 - 49s - loss: 0.4059 - val_loss: 1.6915 - 49s/epoch - 249ms/step\nEpoch 9/100\n198/198 - 49s - loss: 0.3885 - val_loss: 1.5394 - 49s/epoch - 245ms/step\nEpoch 10/100\n198/198 - 49s - loss: 0.3570 - val_loss: 1.9430 - 49s/epoch - 249ms/step\nEpoch 11/100\n198/198 - 49s - loss: 0.3621 - val_loss: 1.6676 - 49s/epoch - 245ms/step\nEpoch 12/100\n198/198 - 49s - loss: 0.3884 - val_loss: 1.5585 - 49s/epoch - 248ms/step\nEpoch 13/100\n198/198 - 49s - loss: 0.3709 - val_loss: 1.7701 - 49s/epoch - 248ms/step\nEpoch 14/100\n198/198 - 49s - loss: 0.4130 - val_loss: 1.4884 - 49s/epoch - 249ms/step\nEpoch 15/100\n198/198 - 49s - loss: 0.4532 - val_loss: 1.6691 - 49s/epoch - 246ms/step\nEpoch 16/100\n198/198 - 49s - loss: 0.4747 - val_loss: 1.4871 - 49s/epoch - 248ms/step\nEpoch 17/100\n198/198 - 48s - loss: 0.5186 - val_loss: 1.6568 - 48s/epoch - 243ms/step\nEpoch 18/100\n198/198 - 47s - loss: 0.5662 - val_loss: 1.4054 - 47s/epoch - 238ms/step\nEpoch 19/100\n198/198 - 48s - loss: 0.6364 - val_loss: 1.3816 - 48s/epoch - 241ms/step\nEpoch 20/100\n198/198 - 48s - loss: 0.7027 - val_loss: 1.3692 - 48s/epoch - 242ms/step\nEpoch 21/100\n198/198 - 47s - loss: 0.6661 - val_loss: 1.5168 - 47s/epoch - 238ms/step\nEpoch 22/100\n198/198 - 48s - loss: 0.6978 - val_loss: 1.4822 - 48s/epoch - 242ms/step\nEpoch 23/100\n198/198 - 48s - loss: 0.6992 - val_loss: 1.2783 - 48s/epoch - 240ms/step\nEpoch 24/100\n198/198 - 48s - loss: 0.6994 - val_loss: 1.3573 - 48s/epoch - 241ms/step\nEpoch 25/100\n198/198 - 47s - loss: 0.7684 - val_loss: 1.2532 - 47s/epoch - 239ms/step\nEpoch 26/100\n198/198 - 48s - loss: 0.7916 - val_loss: 1.2074 - 48s/epoch - 241ms/step\nEpoch 27/100\n198/198 - 47s - loss: 0.7880 - val_loss: 1.2741 - 47s/epoch - 238ms/step\nEpoch 28/100\n198/198 - 48s - loss: 0.8009 - val_loss: 1.2337 - 48s/epoch - 240ms/step\nEpoch 29/100\n198/198 - 47s - loss: 0.7980 - val_loss: 1.3022 - 47s/epoch - 237ms/step\nEpoch 30/100\n198/198 - 48s - loss: 0.8485 - val_loss: 1.1943 - 48s/epoch - 240ms/step\nEpoch 31/100\n198/198 - 47s - loss: 0.8657 - val_loss: 1.2181 - 47s/epoch - 238ms/step\nEpoch 32/100\n198/198 - 48s - loss: 0.8720 - val_loss: 1.1848 - 48s/epoch - 241ms/step\nEpoch 33/100\n198/198 - 47s - loss: 0.8821 - val_loss: 1.2010 - 47s/epoch - 239ms/step\nEpoch 34/100\n198/198 - 47s - loss: 0.8721 - val_loss: 1.2344 - 47s/epoch - 240ms/step\nEpoch 35/100\n198/198 - 47s - loss: 0.8855 - val_loss: 1.1594 - 47s/epoch - 237ms/step\nEpoch 36/100\n198/198 - 47s - loss: 0.8710 - val_loss: 1.1541 - 47s/epoch - 239ms/step\nEpoch 37/100\n198/198 - 47s - loss: 0.8880 - val_loss: 1.1722 - 47s/epoch - 238ms/step\nEpoch 38/100\n198/198 - 48s - loss: 0.9192 - val_loss: 1.1973 - 48s/epoch - 240ms/step\nEpoch 39/100\n198/198 - 47s - loss: 0.9559 - val_loss: 1.1564 - 47s/epoch - 237ms/step\nEpoch 40/100\n198/198 - 48s - loss: 0.9627 - val_loss: 1.1452 - 48s/epoch - 240ms/step\nEpoch 41/100\n198/198 - 47s - loss: 1.0208 - val_loss: 1.1646 - 47s/epoch - 237ms/step\nEpoch 42/100\n198/198 - 47s - loss: 1.0507 - val_loss: 1.1233 - 47s/epoch - 239ms/step\nEpoch 43/100\n198/198 - 47s - loss: 1.0208 - val_loss: 1.1262 - 47s/epoch - 238ms/step\nEpoch 44/100\n198/198 - 47s - loss: 1.0080 - val_loss: 1.1121 - 47s/epoch - 238ms/step\nEpoch 45/100\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[142], line 73\u001b[0m\n\u001b[1;32m     70\u001b[0m optim \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.008\u001b[39m)\n\u001b[1;32m     71\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mloss, optimizer\u001b[38;5;241m=\u001b[39moptim)\n\u001b[0;32m---> 73\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_valid_padded\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ny_pred_probs = model.predict(X_test_padded)\n\n# Convert predictions to class labels\ny_pred = np.argmax(y_pred_probs, axis=-1)\n\n# Convert test labels to class labels\ny_true = np.argmax(y_test.to_numpy(), axis=-1)\n\n# Calculating accuracy\naccuracy = accuracy_score(y_true, y_pred)\nprint(f'Accuracy: {accuracy}')\n\n# Generating classification report\nreport = classification_report(y_true, y_pred)\nprint('Classification Report:')\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T11:03:05.347790Z","iopub.execute_input":"2024-06-06T11:03:05.349767Z","iopub.status.idle":"2024-06-06T11:03:11.900820Z","shell.execute_reply.started":"2024-06-06T11:03:05.349729Z","shell.execute_reply":"2024-06-06T11:03:11.899739Z"},"trusted":true},"execution_count":137,"outputs":[{"name":"stdout","text":"62/62 [==============================] - 6s 68ms/step\nAccuracy: 0.4375\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.51      0.47      0.49       769\n           1       0.38      0.45      0.41       632\n           2       0.42      0.38      0.40       583\n\n    accuracy                           0.44      1984\n   macro avg       0.44      0.43      0.43      1984\nweighted avg       0.44      0.44      0.44      1984\n\n","output_type":"stream"}]}]}